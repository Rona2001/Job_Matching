import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import ast

# Load datasets
offers_df = pd.read_csv('companies_job.csv')
candidates_df = pd.read_csv("candidates_job.csv")

def parse_created_by(field):
    """
    Parse the 'created_by' field from the dataset to extract user ID and values.

    Args:
        field (str): The 'created_by' field in string representation of a dictionary.

    Returns:
        tuple: A tuple containing the user ID (uid) and a list of values.
    """
    parsed = ast.literal_eval(field)
    uid = parsed['uid']
    values = parsed.get('values', [])
    return uid, values

# Apply the parsing function to extract 'uid' and 'values' into separate columns
offers_df[['uid', 'values']] = offers_df['created_by'].apply(lambda x: pd.Series(parse_created_by(x)))
candidates_df[['uid', 'values']] = candidates_df['created_by'].apply(lambda x: pd.Series(parse_created_by(x)))

# Ensure all values in relevant columns are strings
relevant_columns = ['remote_status', 'job_name', 'salary', 'job_time', 
                    'distance', 'contract_time', 'experience', 'availability', 
                    'advantages', 'contract_types', 'study_level']
for col in relevant_columns:
    offers_df[col] = offers_df[col].astype(str)
    candidates_df[col] = candidates_df[col].astype(str)

# Define mappings for additional attributes
remote_status_mapping = {
    'Non': 0,
    'Oui': 1,
    'Full Remote': 2,
    'IndiffÃ©rent': 3
}
availability_mapping = {
    'ğŸ“… ImmÃ©diate': 0,
    'ğŸ“… 1 mois max': 1,
    'ğŸ“… 2 mois max': 2,
    'ğŸ“… 3 mois max': 3,
    'ğŸ“… + de 3 mois': 4
}
contract_type_mapping = {
    'ğŸ“ƒ CDI': 0,
    'ğŸ“ƒ CDD': 1,
    'ğŸ“ƒ Freelance': 2,
    'ğŸ“ƒ Internship': 3,
    'ğŸ“ƒ Part-time': 4
}
job_time_mapping = {
    'â° Temps plein': 0,
    'â° Temps partiel': 1
}
experience_mapping = {
    'ğŸŒ± Sans expÃ©rience': 0,
    'ğŸŒ¿ 1 Ã  3 ans d\'expÃ©rience': 1,
    'ğŸŒ³ 3 Ã  5 ans d\'expÃ©rience': 2,
    'ğŸŒ² 5 Ã  10 ans d\'expÃ©rience': 3,
    'ğŸï¸ Plus de 10 ans d\'expÃ©rience': 4
}
education_mapping = {
    'ğŸ“– Autodidacte': 0,
    'ğŸ“œ DiplÃ´me national du brevet': 1,
    'ğŸ› ï¸ CAP': 2,
    'ğŸ“š BEP': 3,
    'ğŸ“ Bac': 4,
    'ğŸ« DUT': 5,
    'ğŸ§‘â€ğŸ”¬ BTS': 6,
    'ğŸ“ ğŸ“š Licence': 7,
    'ğŸ“ ğŸ“š ğŸ“š Master': 8,
    'ğŸ“ ğŸ”¬ Doctorat': 9
}
salary_mapping = {
    'ğŸ’° Jusquâ€™Ã  20 000 â‚¬': 0,
    'ğŸ’° De 20 000 Ã  30 000 â‚¬': 1,
    'ğŸ’° De 30 000 Ã  40 000 â‚¬': 2,
    'ğŸ’° De 40 000 Ã  55 000 â‚¬': 3,
    'ğŸ’° De 55 000 Ã  70 000 â‚¬': 4,
    'ğŸ’° â• de 70.000 â‚¬': 5
}

values_mapping = {
    'Ã‰galitÃ© des chances ğŸŒˆ': 1,
    'DiversitÃ© et inclusion ğŸŒ': 2,
    'NoRacism ğŸ›‘': 3,
    'Droits de l\'homme âš–ï¸': 4,
    'Ã‰galitÃ© des sexes': 5,
    'Protection de l\'environnement ğŸŒ¿': 6,
    'DurabilitÃ© et Ã©coresponsabilitÃ© ğŸŒ±': 7,
    'Justice sociale ğŸ“': 8,
    'Soutien Ã  l\'Ã©ducation ğŸ“š': 9,
    'Lutte contre la pauvretÃ© âœŠ': 10,
    'AccessibilitÃ© pour tous â™¿': 11,
    'Aide humanitaire ğŸ¥': 12,
    'DÃ©veloppement de compÃ©tences ğŸ› ï¸': 13,
    'Respect de la vie privÃ©e et des donnÃ©es ğŸ”': 14,
    'Action pour le climat â˜€ï¸': 15
}

location_mapping = {
    "Paris": 1,
    "Marseille": 2,
    "Lyon": 3,
    "Toulouse": 4,
    "Nice": 5,
    "Nantes": 6,
    "Strasbourg": 7,
    "Montpellier": 8,
    "Bordeaux": 9,
    "Lille": 10,
    "Rennes": 11,
    "Reims": 12,
    "Le Havre": 13,
    "Cergy": 14,
    "Saint-Ã‰tienne": 15,
    "Toulon": 16,
    "Angers": 17,
    "Grenoble": 18,
    "Dijon": 19,
    "NÃ®mes": 20,
    "Aix-en-Provence": 21,
    "Saint-Quentin-en-Yvelines": 22,
    "Brest": 23,
    "Le Mans": 24,
    "Amiens": 25,
    "Limoges": 26,
    "Tours": 27,
    "Clermont-Ferrand": 28,
    "Villeurbanne": 29,
    "Metz": 30,
    "BesanÃ§on": 31,
    "OrlÃ©ans": 32,
    "Mulhouse": 33,
    "Caen": 34,
    "Rouen": 35,
    "Boulogne-Billancourt": 36,
    "Perpignan": 37,
    "Nancy": 38,
    "Roubaix": 39,
    "Argenteuil": 40,
    "Montreuil": 41,
    "Avignon": 42,
    "Versailles": 43,
    "Pau": 44,
    "La Rochelle": 45,
    "Calais": 46,
    "Antibes": 47,
    "Saint-Denis": 48,
    "Saint-Paul (La RÃ©union)": 49,
    "Le Tampon (La RÃ©union)": 50
}

# Encode categorical features
candidates_df['remote_status_encoded'] = candidates_df['remote_status'].map(remote_status_mapping)
candidates_df['availability_encoded'] = candidates_df['availability'].map(availability_mapping)
candidates_df['contract_type_encoded'] = candidates_df['contract_types'].map(contract_type_mapping)
candidates_df['job_time_encoded'] = candidates_df['job_time'].map(job_time_mapping)
candidates_df['experience_encoded'] = candidates_df['experience'].map(experience_mapping)
candidates_df['education_encoded'] = candidates_df['study_level'].map(education_mapping)
candidates_df['salary_encoded'] = candidates_df['salary'].map(salary_mapping)
candidates_df['localisation_num'] = candidates_df['address'].map(location_mapping)

offers_df['remote_status_encoded'] = offers_df['remote_status'].map(remote_status_mapping)
offers_df['availability_encoded'] = offers_df['availability'].map(availability_mapping)
offers_df['contract_type_encoded'] = offers_df['contract_types'].map(contract_type_mapping)
offers_df['job_time_encoded'] = offers_df['job_time'].map(job_time_mapping)
offers_df['experience_encoded'] = offers_df['experience'].map(experience_mapping)
offers_df['education_encoded'] = offers_df['study_level'].map(education_mapping)
offers_df['salary_encoded'] = offers_df['salary'].map(salary_mapping)

# Fill NaN values with defaults
candidates_df.fillna({
    'remote_status_encoded': 3,  # Default to 'IndiffÃ©rent'
    'availability_encoded': 4,   # Default to 'ğŸ“… + de 3 mois'
    'contract_type_encoded': 0,  # Default to 'ğŸ“ƒ CDI'
    'job_time_encoded': 0,       # Default to 'â° Temps plein'
    'experience_encoded': 0,     # Default to 'ğŸŒ± Sans expÃ©rience'
    'education_encoded': 0,      # Default to 'ğŸ“– Autodidacte'
    'salary_encoded': 0           # Default to 'ğŸ’° Jusquâ€™Ã  20 000 â‚¬'
}, inplace=True)

offers_df.fillna({
    'remote_status_encoded': 3,
    'availability_encoded': 4,   # Default to 'ğŸ“… + de 3 mois'
    'contract_type_encoded': 0,  # Default to 'ğŸ“ƒ CDI'
    'job_time_encoded': 0,       # Default to 'â° Temps plein'
    'experience_encoded': 0,     # Default to 'ğŸŒ± Sans expÃ©rience'
    'education_encoded': 0,      # Default to 'ğŸ“– Autodidacte'
    'salary_encoded': 0          # Default to 'ğŸ’° Jusquâ€™Ã  20 000 â‚¬'
}, inplace=True)

# Drop unnecessary columns after encoding
candidates_df.drop(['remote_status', 'availability', 'contract_types', 'job_time', 'experience', 'study_level', 'salary'], axis=1, inplace=True)
offers_df.drop(['remote_status', 'availability', 'contract_types', 'job_time', 'experience', 'study_level', 'salary'], axis=1, inplace=True)

# Calculate cosine similarity between candidates and offers based on encoded features
candidates_features = candidates_df[['remote_status_encoded', 'availability_encoded', 'contract_type_encoded',
                                     'job_time_encoded', 'experience_encoded', 'education_encoded', 'salary_encoded']]
offers_features = offers_df[['remote_status_encoded', 'availability_encoded', 'contract_type_encoded',
                             'job_time_encoded', 'experience_encoded', 'education_encoded', 'salary_encoded']]

similarity_matrix = cosine_similarity(candidates_features, offers_features)

def get_all_best_match_candidates(offer_id):
    """
    Get the top 10 best match candidates for a given job offer based on cosine similarity.

    Args:
        offer_id (str): The unique identifier of the job offer.

    Returns:
        list: A list of dictionaries containing the best match candidates and their similarity scores.
    """
    offer_index = offers_df[offers_df['uid'] == offer_id].index
    if len(offer_index) == 0:
        return "Offer not found"
    offer_index = offer_index[0]
    best_match_indices = similarity_matrix[:, offer_index].argsort()[::-1][:10]
    best_matches = []
    for idx in best_match_indices:
        best_match_candidate = candidates_df.iloc[idx]['uid']
        similarity_score = similarity_matrix[idx, offer_index]
        best_matches.append({
            'Best Match Candidate': best_match_candidate,
            'Similarity Score': similarity_score
        })
    return best_matches

# Example usage
offer_id = 'DLM61VJ6lJgrrE14AORpNmJVrfi1'  # Change this to the ID of the job offer you want to find the best match candidates for
results = get_all_best_match_candidates(offer_id)
for result in results:
    print(result)
